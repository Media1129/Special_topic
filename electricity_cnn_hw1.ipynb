{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from PIL import Image #python image library\n",
    "import numpy as np\n",
    "import os \n",
    "root = \"training/\"\n",
    "filename=\"train.tfrecords\"\n",
    "def write_record(root,filename):\n",
    "    writer=tf.python_io.TFRecordWriter(filename)\n",
    "    for i in range(10):\n",
    "        class_path = root+\"Sample0{:02}/\".format(i+1)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            if img_name == '.DS_Store':\n",
    "                continue\n",
    "            img_path = class_path+img_name\n",
    "            img = Image.open(img_path).convert(\"L\") #轉成grayscale\n",
    "            img_raw = img.tobytes()\n",
    "            labels  = [0]*10\n",
    "            labels[i] = 1\n",
    "            #Example 裡面裝features\n",
    "            #features裡面裝feature\n",
    "            example=tf.train.Example(features=tf.train.Features(\n",
    "              feature={\n",
    "                \"label\":tf.train.Feature(int64_list=tf.train.Int64List(value=labels)),\n",
    "                'img_raw':tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "                                                                    value=[img_raw]))\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())\n",
    "    writer.close()        \n",
    "write_record(root,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_record(filename,batch_size,num_epochs):\n",
    "    #建立檔名佇列\n",
    "    filename_queue = tf.train.string_input_producer([filename],num_epochs=num_epochs)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialized_example = reader.read(filename_queue)\n",
    "    #將「tf.train.Example」檔案解析為「tf.train.Features」\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'label':tf.FixedLenFeature([10],tf.int64),\n",
    "                                           'img_raw':tf.FixedLenFeature([],tf.string)\n",
    "                                       })\n",
    "    #將tobyte()改寫回來成tf.uint8\n",
    "    img = tf.decode_raw(features['img_raw'],tf.uint8)\n",
    "    img = tf.reshape(img,(128,128,1))\n",
    "    img = tf.cast(img,tf.float32)/255-0.5\n",
    "    label = tf.cast(features['label'],tf.float32)\n",
    "    batch_xs,batch_ys = tf.train.shuffle_batch([img,label],batch_size=batch_size,\n",
    "                        capacity=2000,min_after_dequeue=1000)\n",
    "    #capacity是隊列的長度\n",
    "    #min_after_dequeue是 隊列至少剩下min_after_dequeue個數據\n",
    "    #min_after_dequeue越大，數據越亂\n",
    "    return batch_xs,batch_ys  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#建立權重weight張量\n",
    "def weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1),name='W')\n",
    "#建立偏差(bias)張量\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1,shape=shape),name='b')\n",
    "#定義conv2d函數，用於進行卷積運算\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "#建立max_pool_2*2函數\n",
    "def max_pool_2_2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "with tf.name_scope('Input_Layer'):\n",
    "    x = tf.placeholder(\"tf.float32\",shape=[None,128,128,1],name=\"x\")\n",
    "with tf.name_scope('C1_Conv'):\n",
    "    W1 = weight([5,5,1,16])\n",
    "    b1 = bias([16])\n",
    "    Conv1 = conv2d(x,W1) + b1\n",
    "    C1_Conv = tf.nn.relu(Conv1)\n",
    "with tf.name_scope('C1_Pool'):\n",
    "    C1_Pool = max_pool_2_2(C1_Conv)\n",
    "with tf.name_scope('C2_Conv'):\n",
    "    W2 = weight([5,5,16,36])\n",
    "    b2 = bias([36])\n",
    "    Conv2 = conv2d(C1_Pool,W2)+b2\n",
    "    C2_Conv = tf.nn.relu(Conv2)\n",
    "with tf.name_scope('C2_Pool'):\n",
    "    C2_Pool = max_pool_2_2(C2_Conv)\n",
    "with tf.name_scope('D_Flat'):\n",
    "    D_Flat = tf.reshape(C2_Pool,[-1,32*32*36])\n",
    "    \n",
    "with tf.name_scope('D_Hidden_Layer'):\n",
    "    W3 = weight([32*32*36,128])\n",
    "    b3 = bias([128])\n",
    "    D_Hidden = tf.nn.relu(tf.matmul(D_Flat,W3)+b3)\n",
    "    D_Hidden_Dropout = tf.nn.dropout(D_Hidden,keep_prob=0.8)\n",
    "with tf.name_scope('Output_Layer'):\n",
    "    W4 = weight([128,10])\n",
    "    b4 = bias([10])\n",
    "    y_predict = tf.nn.softmax(tf.matmul(D_Hidden_Dropout,W4)+b4)\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    y_label = tf.placeholder(\"tf.float32\",shape=[None,10],name=\"y_label\")\n",
    "    loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\n",
    "                                   (logits=y_predict,labels=y_label))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss_function)\n",
    "    \n",
    "with tf.name_scope(\"evaluate_model\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(y_label,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"tf.float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_19:0\", shape=(), dtype=uint8)\n",
      "test\n",
      "loss:  2.3608816\n",
      "pred:  [5 5 5 5 5 5 5 5 5 5]\n",
      "ans:  [6 4 7 7 7 7 5 4 2 7]\n",
      "test\n",
      "loss:  2.3521855\n",
      "pred:  [5 5 5 7 5 5 5 5 5 5]\n",
      "ans:  [1 6 5 9 2 2 4 0 3 0]\n",
      "test\n",
      "loss:  2.0562038\n",
      "pred:  [7 7 7 5 7 3 3 5 7 3]\n",
      "ans:  [7 4 7 2 7 4 8 0 2 3]\n",
      "test\n",
      "loss:  2.078605\n",
      "pred:  [5 3 3 3 7 5 3 3 3 3]\n",
      "ans:  [5 5 3 4 7 6 4 6 9 2]\n",
      "test\n",
      "loss:  2.2609138\n",
      "pred:  [5 5 5 5 7 7 3 3 5 3]\n",
      "ans:  [6 6 6 6 2 7 8 3 0 2]\n",
      "test\n",
      "loss:  1.8554935\n",
      "pred:  [4 1 3 4 5 3 3 1 1 3]\n",
      "ans:  [0 1 3 0 5 2 8 1 1 3]\n",
      "test\n",
      "loss:  1.8666184\n",
      "pred:  [3 5 3 7 1 1 7 5 1 4]\n",
      "ans:  [2 5 3 7 2 4 7 6 1 0]\n",
      "test\n",
      "loss:  1.9537203\n",
      "pred:  [4 3 5 2 9 4 2 4 4 4]\n",
      "ans:  [4 3 9 0 0 4 2 0 9 4]\n",
      "test\n",
      "loss:  1.6604881\n",
      "pred:  [9 1 1 5 3 9 3 7 6 3]\n",
      "ans:  [9 1 1 5 3 9 8 7 6 3]\n",
      "test\n",
      "loss:  1.4634016\n",
      "pred:  [9 3 7 6 9 1 3 5 9 2]\n",
      "ans:  [9 3 7 5 9 1 3 5 9 2]\n",
      "test\n",
      "loss:  1.5689378\n",
      "pred:  [9 1 3 7 9 9 9 7 6 7]\n",
      "ans:  [9 1 8 7 9 9 9 7 6 7]\n",
      "test\n",
      "loss:  1.9450058\n",
      "pred:  [7 4 9 9 9 3 6 1 9 6]\n",
      "ans:  [7 0 0 0 9 8 6 1 9 0]\n",
      "test\n",
      "loss:  1.7626082\n",
      "pred:  [6 6 2 1 2 9 1 9 1 3]\n",
      "ans:  [6 0 2 1 2 9 1 8 1 8]\n",
      "test\n",
      "loss:  1.5605643\n",
      "pred:  [2 2 5 9 1 3 6 9 1 7]\n",
      "ans:  [2 2 5 9 1 3 6 0 1 7]\n",
      "test\n",
      "loss:  1.5750778\n",
      "pred:  [4 1 3 6 5 6 3 4 4 9]\n",
      "ans:  [4 1 3 8 5 6 3 4 4 9]\n",
      "test\n",
      "loss:  1.6653191\n",
      "pred:  [3 1 9 2 1 2 4 1 9 3]\n",
      "ans:  [3 1 8 2 1 2 4 1 9 8]\n",
      "test\n",
      "loss:  1.5600057\n",
      "pred:  [7 1 5 1 1 2 9 3 9 4]\n",
      "ans:  [7 1 5 1 1 2 9 8 9 4]\n",
      "test\n",
      "loss:  1.46376\n",
      "pred:  [6 6 1 7 1 7 7 6 4 9]\n",
      "ans:  [6 6 1 7 1 7 7 6 4 9]\n",
      "test\n",
      "loss:  1.4615004\n",
      "pred:  [5 1 9 1 1 3 9 2 4 5]\n",
      "ans:  [5 1 9 1 1 3 9 2 4 5]\n",
      "test\n",
      "loss:  1.8527607\n",
      "pred:  [9 3 6 2 5 2 1 7 9 1]\n",
      "ans:  [8 8 0 2 5 2 1 7 0 1]\n",
      "test\n",
      "loss:  1.5592352\n",
      "pred:  [2 5 6 6 1 9 5 7 6 7]\n",
      "ans:  [2 5 0 6 1 9 5 7 6 7]\n",
      "test\n",
      "loss:  1.5607954\n",
      "pred:  [6 4 7 6 1 7 4 7 1 5]\n",
      "ans:  [8 4 7 6 1 7 4 7 1 5]\n",
      "test\n",
      "loss:  1.5646698\n",
      "pred:  [7 5 2 4 4 2 1 6 2 9]\n",
      "ans:  [7 5 2 4 4 2 1 6 2 8]\n",
      "test\n",
      "loss:  1.6580178\n",
      "pred:  [2 5 2 9 2 9 9 1 9 6]\n",
      "ans:  [2 5 2 9 2 9 8 1 9 0]\n",
      "test\n",
      "loss:  1.7480977\n",
      "pred:  [9 7 6 5 9 2 7 2 9 9]\n",
      "ans:  [9 7 8 5 8 2 7 2 0 9]\n",
      "test\n",
      "loss:  1.4613104\n",
      "pred:  [7 3 7 1 6 6 9 5 5 9]\n",
      "ans:  [7 3 7 1 6 6 9 5 5 9]\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "b_img,b_lab = read_record(\"train.tfrecords\",10,20)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    try:\n",
    "        i=0\n",
    "        while not coord.should_stop():\n",
    "            i+=1\n",
    "            img,lab = sess.run([b_img,b_lab])\n",
    "            sess.run(optimizer,feed_dict={x:img,y_label:lab})\n",
    "            if i%50 == 0:\n",
    "                print(\"test\")\n",
    "                print(\"loss: \",sess.run(loss_function,feed_dict={x:img,y_label:lab}))\n",
    "                print(\"pred: \",np.argmax(sess.run(y_predict,feed_dict={x:img}),axis=1))\n",
    "                print(\"ans: \" ,np.argmax(lab,axis=1))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"Done training\")\n",
    "        saver.save(sess,\"./example.ckpt\")\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
